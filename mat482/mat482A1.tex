\documentclass[12pt, a4paper]{article}
\usepackage[lmargin =0.5 in, 
rmargin=0.5in, 
tmargin=1in,
bmargin=0.5in]{geometry}
\geometry{letterpaper}
\usepackage{tikz-cd}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{blindtext}
\usepackage{titlesec}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{cool}
\usepackage{thmtools}
\usepackage{hyperref}
\graphicspath{ }					%path to an image

%-------- sexy font ------------%
%\usepackage{libertine}
%\usepackage{libertinust1math}
 
%\usepackage{mlmodern}				% very nice and classic
%\usepackage[utopia]{mathdesign}
%\usepackage[T1]{fontenc}


\usepackage{mlmodern}
\usepackage{eulervm}
%\usepackage{tgtermes} 				%times new roman
%-------- sexy font ------------%


% Problem Styles
%====================================================================%


\newtheorem{problem}{Problem}


\theoremstyle{definition}
\newtheorem{thm}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{prop}{Proposition}
\newtheorem{cor}{Corollary}
\newtheorem{fact}{Fact}
\newtheorem{defn}{Definition}
\newtheorem{example}{Example}
\newtheorem{question}{Question}

\newtheorem{manualprobleminner}{Problem}

\newenvironment{manualproblem}[1]{%
	\renewcommand\themanualprobleminner{#1}%
	\manualprobleminner
}{\endmanualprobleminner}

\newcommand{\penum}{ \begin{enumerate}[label=\bf(\alph*), leftmargin=0pt]}
	\newcommand{\epenum}{ \end{enumerate} }

% Math fonts shortcuts
%====================================================================%

\newcommand{\ring}{\mathcal{R}}
\newcommand{\N}{\mathbb{N}}                           % Natural numbers
\newcommand{\Z}{\mathbb{Z}}                           % Integers
\newcommand{\R}{\mathbb{R}}                           % Real numbers
\newcommand{\C}{\mathbb{C}}                           % Complex numbers
\newcommand{\F}{\mathbb{F}}                           % Arbitrary field
\newcommand{\Q}{\mathbb{Q}}                           % Arbitrary field
\newcommand{\PP}{\mathcal{P}}                         % Partition
\newcommand{\M}{\mathcal{M}}                         % Mathcal M
\newcommand{\eL}{\mathcal{L}}                         % Mathcal L
\newcommand{\T}{\mathbb{T}}                         % Mathcal T
\newcommand{\U}{\mathcal{U}}                         % Mathcal U\\
\newcommand{\V}{\mathcal{V}}                         % Mathcal V

% symbol shortcuts
%====================================================================%

\newcommand{\bd}{\partial}
\newcommand{\grad}{\nabla}
\newcommand{\lam}{\lambda}
\newcommand{\imp}{\implies}
\newcommand{\all}{\forall}
\newcommand{\exs}{\exists}
\newcommand{\delt}{\delta}
\newcommand{\ep}{\varepsilon}
\newcommand{\ra}{\rightarrow}
\newcommand{\vph}{\varphi}

\newcommand{\ol}{\overline}
\newcommand{\f}{\frac}
\newcommand{\lf}{\lfrac}
\newcommand{\df}{\dfrac}

% bracketting shortcuts
%====================================================================%
\newcommand{\abs}[1]{\left| #1 \right|}
\newcommand{\ssubset}{\subset\joinrel\subset}
\newcommand{\babs}[1]{\Big|#1\Big|}
\newcommand{\bound}{\Big|}
\newcommand{\BB}[1]{\left(#1\right)}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\artanh}{\mathrm{artanh}}
\newcommand{\Med}{\mathrm{Med}}
\newcommand{\Cov}{\mathrm{Cov}}
\newcommand{\Corr}{\mathrm{Corr}}
\newcommand{\tr}{\mathrm{tr}}
\newcommand{\Range}[1]{\mathrm{range}(#1)}
\newcommand{\Null}[1]{\mathrm{null}(#1)}
\newcommand{\lan}{\langle}
\newcommand{\ran}{\rangle}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\inn}[1]{\lan#1\ran}
\newcommand{\op}[1]{\operatorname{#1}}
\newcommand{\bmat}[1]{\begin{bmatrix}#1\end{bmatrix}}
\newcommand{\pmat}[1]{\begin{pmatrix}#1\end{pmatrix}}
\newcommand{\vmat}[1]{\begin{vmatrix}#1\end{vmatrix}}

\newcommand{\amogus}{{\bigcap}\kern-0.8em\raisebox{0.3ex}{$\subset$}}
\newcommand{\Note}{\textbf{Note: }}
\newcommand{\Aside}{{\bf Aside: }}
%restriction
%\newcommand{\op}[1]{\operatorname{#1}}
%\newcommand{\done}{$$\mathcal{QED}$$}

%====================================================================%


\setlength{\parindent}{0pt}      	% No paragraph indentations
\pagestyle{fancy}
\fancyhf{}							% fancy header

\setcounter{secnumdepth}{0}			% sections are numbered but numbers do not appear
\setcounter{tocdepth}{2} 			% no subsubsections in toc

%template
%====================================================================%
%\begin{manualproblem}{1}
%Spivak.
%\end{manualproblem}

%\begin{proof}[Solution]
%\end{proof}

%----------- or -----------%

%\begin{problem} 		
%\end{problem}	

%\penum
%	\item
%\epenum
%====================================================================%


\newcommand{\Course}{MAT482}
\newcommand{\hwNumber}{1}

%preamble

\title{Elliptic PDE's HW1}
\author{Alexander Neagoe }
\date{\today}
\lhead{\Course A\hwNumber}
\rhead{\thepage}
%\cfoot{\thepage}


%====================================================================%
\begin{document}

\maketitle

\begin{problem}
\end{problem}
If $u$ is constant then the result is true for $C=1$. Suppose now that $u$ is not constant. Consider the case where $\Omega  = B_1(0)$ and $\Omega^\prime = B_r(0)$, where $r<1$.  
\newpage
\begin{problem}
\end{problem}
Define the coordinate system $y = Ax$. We have that $y_i = \sum_j a_{ij}x_j$ and by orthogonality $x_i = \sum_{j} a_{ji}y_j$. We can write the Laplacian in the $x$ coordinates as: 
$$\Delta_x u = \sum_{i ,j} \delta_{ij} \partial_{ij}u.$$
Using the chain rule, we compute that 
$$\partial_{x_i} u = \sum_k \partial_{y_k}u \frac{\partial y_k}{\partial x_i} = \sum_k \partial_{y_k} a_{ki}u.$$
We can therefore write the Laplacian as: 
$$\Delta_x u = \sum_{i,j,k , l} \delta_{ij} a_{ki}a_{lj} \partial_{y_l y_k} u = \sum_{k, l} \partial_{y_l y_k} \left[ \sum_{i,j}\delta_{ij} a_{ki}a_{lj} \right]u.$$
Since $A$ is an orthogonal matrix, $\sum_{i,j}\delta_{ij} a_{ki}a_{lj}$ must be $\delta_{kl}.$
We conclude
$$f(x) = \Delta_x u = \sum_{k,l} \partial_{y_k,y_l}u = \Delta_y u = f(y) = f(Ax).$$
\newpage
\begin{problem}
\end{problem}
Recall the the product rule for the laplacian: 
$$\Delta(uv) = v \Delta u + 2\grad u \cdot \grad v + u \Delta v,$$
And Green's first identity:
$$\int_{B_r(0)} \grad \psi \cdot \grad \varphi = \oint_{\bd B_r(0)} \psi \grad \varphi - \int_{B_r(0)} \psi \Delta \varphi.$$
We integrate the product rule for $v= \frac{1}{|x|^{n-2}}$, and apply Green's first identity to get:
$$\int_{B_r(0)}\Delta \left( \frac{u}{|x|^{n-2}} \right) = \int_{B_r(0)} \frac{\Delta u}{|x|^{n-2}}  + 2 \left( \oint_{\bd B_r(0)} u \cdot \grad \frac{1}{|x|^{n-2}} - \int_{B_r(0)}u \cdot \Delta \frac{1}{|x|^{n-2}}\right) + \int_{B_r(0)} u \cdot \Delta \frac{1}{|x|^{n-2}}.$$
We apply the Divergence theorem to the lefthand side: 
$$\int_{B_r(0)}\Delta \left( \frac{u}{|x|^{n-2}} \right) = \oint_{\bd B_r(0)} \grad\left(\frac{u}{|x|^{n-2}}\right) = \oint_{\bd B_r(0)} \frac{1}{|x|^{n-2}} \grad u + \oint_{\bd B_r(0)}u \grad \frac{1}{|x|^{n-2}}.$$
We have that:
$$\grad \frac{1}{|x|^{n-2}} = \frac{(2-n)}{|x|^{n}} x.$$
Therefore we can write the lefthand side as: 
$$\oint_{\bd B_r(0)} \frac{1}{|x|^{n-2}} \grad u  + \oint_{\bd B_r(0)} g(x) \frac{(2-n)}{|x|^n}x \cdot x d\sigma(x) =\oint_{\bd B_r(0)}\frac{1}{|x|^{n-2}} \grad u + \frac{(2-n)}{|r|^{n-1}} \oint_{\bd B_r(0)} g(x) d\sigma(x).$$
Now on the righthand side, we have:
$$\int_{B_r(0)} \frac{f}{|x|^{n-2}} + 2 \frac{(2-n)}{|r|^{n-1}} \oint_{\bd B_r(0)} g(x) d\sigma(x) - \int_{B_r(0)} u \cdot \Delta \frac{1}{|x|^{n-2}} .$$
Equality of both of these gives us that:
$$\int_{B_r(0)} u \cdot \Delta \frac{1}{|x|^{n-2}} = \frac{(2-n)}{|r|^{n-1}} \oint_{\bd B_r(0)} g(x) d\sigma(x) + \int_{B_r(0)} \frac{f}{|x|^{n-2}} - \oint_{\bd B_r(0)} \grad u \cdot \frac{1}{|x|^{n-2}}.$$
By the Divergence theorem we can simplify the last integral as:
$$\oint_{\bd B_r(0)} \grad u \cdot \frac{1}{|x|^{n-2}} = \oint_{\bd B_r(0)} \frac{\grad u}{r^{n-2}} = \int_{B_r(0)} \frac{f}{|r|^{n-2}} $$
Since $\Delta \frac{1}{|x|^{n-2}}= \omega_n n(2-n)\delta_0$ we get that:
$$\omega_n n(2-n) u(0) = \frac{(2-n)}{r^{n-1}} \oint_{\bd B_r(0)}g(x)d\sigma(x) + \int_{B_r(0)} \left( \frac{1}{|x|^{n-2}} - \frac{1}{r^{n-2}}\right) f dx.$$
Dividing gives us: 
$$u(0) = \frac{1}{n \omega_n r^{n-1}} \oint_{\bd B_r(0)} g(x)d \sigma(x) + \frac{1}{n(n-2)\omega_n} \int_{B_r(0)} \left( \frac{1}{r^{n-2}} - \frac{1}{|x|^{n-2}} \right) f(x)dx.$$
It remains to show that the application of the divergence theorem is legitimate. 
We have that $$\int_{B_r(0)} \Delta \left(\frac{u}{|x|^{n-2}}\right)$$
\newpage
\begin{problem}
\end{problem}
\penum
\item Define $D_R = \{x:  1 \leq |x| \leq R\}$ and define $u_\ep  = u(x) - \ep \log|x|$.  Since $\log|x|$ is harmonic on $\R^2$, we have that $u_\ep$ is subharmonic. 
Therefore the sup of $u_\ep$ on $D_R$ is attained on the boundary. We claim that it cannot be attained when $|x| = R$ for a sufficiently large $R$. Since $|x|= 1$ is compact, $u_\ep$ attains some supremum along $|x|=1$. However since $u$ is bounded and $\log |x|$ is increasing as a function of $|x|$, for large enough $R$ we will have that $\sup_{|x| = R} u_\ep  \leq  \sup_{|x| = 1} u_\ep$. Certainly this will hold for all $R^\prime \geq R$. Therefore we have that 
$$\sup_{|x|\geq 1} u_\ep = \sup_{|x| = 1} u_\ep = \sup_{|x| = 1}u.$$
The last equality follows from the fact that $\log|x|$ vanishes on $|x|=1$. 
\item 
For that for all $\ep >0$, $u(x) = u_\ep + \ep \log |x|$. Using what was shown above, we have that 
$$u(x) \leq \sup_{|x| = 1} u_\ep + \ep \log |x| = \sup_{|x| = 1} u + \ep \log |x|. $$
Since this holds for all $\ep>0$ we have that 
$$u(x) \leq \sup_{|x| = 1} u(x).$$
The point at which $u(x)$ attains its supremum has norm 1, and thus is in the interiour of the domain of $u$. Therefore $u$ is constant on every compact set containing $S^1$. Since $\R^2$ is connected it follows that $u$ is constant. 
\item 
Let $f$ be a smooth function so that $\int_{\R^3} f =1$, $0 \leq f \leq 1$ and $\text{supp } f \subset \subset B_1(0)$. Then we have that $u(x) = \int_{\R^3} \frac{f(y)}{|x-y|} dy$ is subharmonic, since $\Delta u = f$ i.e. since we are convoluting with the fundamental solution of Laplac's equation. We have that $u$ is bounded as well since 
$$|u(x)| \leq \int_{\R^3} \frac{|f(y)|}{|x-y|} dy \leq \int_{B_1(0)} \frac{1}{|x|} dy \leq C. $$
The reason this works in $\R^3$ is that the fundamental solution to the laplace equation for $\R^n$ when $n=2$ is logarithm, which has a singularity at $0$ but also tends to infinity as $|x|\to \infty$. For $n=2$ this issue does not happen since the fundamental solutions look like $\frac{1}{|x|^{n-2}}$, which are bounded as $|x| \to \infty$. 
\epenum
\newpage
\begin{problem}
\end{problem}
We first claim that $D(\eta u)$ exists. For any $\varphi \in C_c^\infty(\Omega)$, the following is true: 
$$\int u \cdot D(\varphi \cdot \eta) = - \int \varphi \cdot \eta \cdot Du.$$
Since on smooth functions, the weak derivative agrees with the usual derivative, we have that $$\int u \cdot D(\varphi \cdot \eta) = \int u \left(\eta D\varphi + \varphi D \eta\right).$$
Rearranging the first equation we get that 
$$\int \eta u \cdot D\varphi = - \int\varphi \left( \eta Du + u D \eta \right).$$
This is exactly the definition of $D(\eta u)$. We now claim that $\eta u \in W^{1,p}(\Omega)$.
The weak derivative exists by the above computation. It remains to show that it belongs to $L^p(\Omega)$. First we have that $\eta u$ belongs to $L^p(\Omega)$ for all $\eta \in C_c^\infty(\Omega)$, since $\eta$ is bounded above by some constant and $u\in L^p(\Omega)$. We have that $\eta Du, u D\eta\in L^p(\Omega)$ for the same reason. Their sum also belongs to $L^p(\Omega)$, so $D(\eta u)\in L^p(\Omega)$. 
\newpage
\begin{problem}
\end{problem}
First consider the function $P(x) e^{-x}$. We claim that $\lim_{x\to \infty} P(x)e^{-x} =0 $. It is sufficient to show this is true for $P(x) = x^n$. We proceed by induction. When $n=1$ we have that by L'Hopitals rule, 
$$\lim_{x\to \infty} xe^{-x} = \lim_{x \to \infty} e^{-x} = 0.$$
Suppose that this result holds for $n$. Using L'Hopitals rule and induction hypothesis:
$$\lim_{x \to \infty} x^{n+1}e^{-x} = \lim_{x\to \infty} (n+1)x^n e^{-x} = 0. $$
We can extend to any polynomial by linearity of limits. 
Now consider the function $\eta(x)$ as defined. We must show that as $\lim_{|x|\to 1^-} D^{\alpha}e^{\frac{1}{|x|^2-1}} = 0$, for any multi-index $\alpha$. We perform a change of variables within the limit. Set $y = \frac{1}{|x|^2-1}$ so that the limit becomes $\lim_{y \to \infty} D^\alpha e^{-y}$. For any $\alpha$, $D^\alpha e^{-y} = P(y)e^{-y}$ by iterating the product rule for some polynomial $P(y)$. The limit is $0$ by above. 
\newpage
\begin{problem}
\end{problem}
Define $p(x)$ as in problem $6$, normalized so that $\int_{B_1(0)} p(x) = 1$. 
For $\ep>0$ define $p_\ep(x) = \frac{1}{\ep^n}p\left(\frac{x}{\ep}\right)$. By change of variables, we have that $\int_{B_\ep(0)} p_\ep(x) = 1$. 
Given $U \ssubset V$ we can find a set $W$ so that $U \ssubset W \ssubset V$, using topological properties of $\R^n$. Let $\chi_W$ be the indicator function of $W$. Define $\eta(x) = \chi_W \ast p_\ep(x)$ for $\ep < \min \{d(V, \bd W), d(W, \bd U)\}$. This function will be smooth since $p$ is. It remains to show it is $1$ on $V$ and $0$ on $U^c$. For $x\in V$, 
$$\eta(x) = \int_{\R^n} \chi_W (y) \cdot p_\ep(x-y) dy = \int_{B_\ep(x)} p_\ep (y) dy =1.$$
Where we use the fact that $\chi_W$ is $1$ on $B_\ep(x)$, and $p_\ep$ vanishes outside of this ball. Our choice of $\ep$ ensures that such ball will be contained in $W$. Now suppose that $x\in U^c$. Then
$$\eta(x) = \int_{\R^n} \chi_W \cdot p_\ep(x-y) dy = 0$$
Since the support of $p$ is disjoint from $W$, by our choice of $\ep$. 
\newpage
\begin{problem}
\end{problem}
We first claim that given an open cover $\{V_i\}_{\{1,2 \dots , n\}}$, we can refine to another open cover $\{V_i^\prime\}$ so that $V_i^\prime \subset V_i$. We define $C_1 = V_1 \setminus \{V_2 \cup V_3 \dots \cup V_n\}$, $C_2 = V_2 \setminus\{C_1 \cup V_3 \dots \cup V_n\}$ and so on. 
For each $i$ , $C_i \ssubset V_i$ since $C_i$ is closed in $V_i$. We take $V_i^\prime$ to be so that $C_i \ssubset V_i^\prime \ssubset V_i$. We claim that $\{V_i\}$ is an open cover of $U$. For any $x\in U$ there is a maximal $k$ so that $x\in V_k$. By the construction of the $V_i^\prime$'s we have that $x\in V_1^\prime \cup \dots V_k^\prime$.
Hence they form an open cover. Take $\psi_i$ according to problem 7 so that $\psi_i\equiv 1$ on $V_i^\prime$ and $\psi_i \equiv 0$ on $V_i^c$. Since $V_i^\prime$ forms an open cover, at any $x$ at least one $\psi_i$ will be nonzero. We define $\eta_i = \frac{\psi_i(x)}{\sum_{i=1}^n \psi_i(x)}$. This is a quotient of smooth functions, and the denominator is non-vanishing. Therefore it is smooth. Furthermore, $\text{supp } \eta_i \subset V_i$ by construction and $\sum_{i} \eta_i = 1$. 
\newpage
\begin{problem}
\end{problem}
\newpage
\begin{problem}
\end{problem}
\penum
\item 
Suppose that $\{x_n\}$ converges to some $v \in \mathcal{H}$. Then we must have that $\norm{x_n - v}^2\to 0$ as $n \to \infty$. This is the same as saying that $\inn{x_n - v, x_n-v} \to 0$. Using bilinearity, we get:
$$\inn{x_n - v, x_n-v}  = \norm{x_n}^2 - 2 Re(\inn{x_n,v}) + \norm{v}^2. $$ Since $\norm{v} <\infty$ and $\norm{v}^2 = \sum_{n=1}^\infty |\inn{x_n,v}|^2$ we must have that $Re(\inn{x_n,v}) \to 0$. Since $\{x_n\}$ is orthonormal, we have that 
$$\norm{x_n}^2 - 2Re(\inn{x_n,v}) + \norm{v}^2 = 1 - 2 Re(\inn{x_n,v}) + \norm{v}^2 \to 1 + \norm{v}^2 \geq 1.$$
Thus this sequence cannot converge. 
\item For any vector $v\in \mathcal{H}$ we have that $v = \sum_{i=1}^\infty \inn{x_n,v}x_n$ and $\norm{v}^2 = \sum_{i=1}^\infty |\inn{x_n,v}|^2$. Therefore we must have that $\inn{x_n,v} \to 0$ or $\inn{x_n,v} \to \inn{0,v}$. Thus $\{x_n\}$ converges weakly to $0$. 

\epenum

\end{document}